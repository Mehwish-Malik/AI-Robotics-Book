"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[278],{5121:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>m,frontMatter:()=>r,metadata:()=>o,toc:()=>d});var s=i(4848),t=i(8453);const r={sidebar_position:1},a="Chapter 13: Simulation Environments",o={id:"modules/module-5-applications/chapter-13-simulation",title:"Chapter 13: Simulation Environments",description:"Summary",source:"@site/docs/modules/module-5-applications/chapter-13-simulation.md",sourceDirName:"modules/module-5-applications",slug:"/modules/module-5-applications/chapter-13-simulation",permalink:"/docs/modules/module-5-applications/chapter-13-simulation",draft:!1,unlisted:!1,editUrl:"https://github.com/Mehwish-Malik/AI-Robotics-Book.git/docs/modules/module-5-applications/chapter-13-simulation.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Chapter 12: Decision Making and Autonomy",permalink:"/docs/modules/module-4-ai/chapter-12-decision-making"},next:{title:"Chapter 14: Real-World Deployment Challenges",permalink:"/docs/modules/module-5-applications/chapter-14-real-world-deployment"}},l={},d=[{value:"Summary",id:"summary",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Introduction to Simulation in Robotics",id:"introduction-to-simulation-in-robotics",level:2},{value:"Benefits of Simulation",id:"benefits-of-simulation",level:3},{value:"Simulation Challenges",id:"simulation-challenges",level:3},{value:"Physics Simulation Fundamentals",id:"physics-simulation-fundamentals",level:2},{value:"Rigid Body Dynamics",id:"rigid-body-dynamics",level:3},{value:"Contact and Collision Detection",id:"contact-and-collision-detection",level:3},{value:"Constraint Solving",id:"constraint-solving",level:3},{value:"Major Simulation Platforms",id:"major-simulation-platforms",level:2},{value:"Gazebo",id:"gazebo",level:3},{value:"PyBullet",id:"pybullet",level:3},{value:"Webots",id:"webots",level:3},{value:"MuJoCo",id:"mujoco",level:3},{value:"Isaac Gym",id:"isaac-gym",level:3},{value:"Sensor Simulation",id:"sensor-simulation",level:2},{value:"Camera Simulation",id:"camera-simulation",level:3},{value:"IMU Simulation",id:"imu-simulation",level:3},{value:"Force/Torque Sensor Simulation",id:"forcetorque-sensor-simulation",level:3},{value:"LIDAR Simulation",id:"lidar-simulation",level:3},{value:"Sim-to-Real Transfer",id:"sim-to-real-transfer",level:2},{value:"The Reality Gap Problem",id:"the-reality-gap-problem",level:3},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"System Identification",id:"system-identification",level:3},{value:"Domain Adaptation",id:"domain-adaptation",level:3},{value:"Technical Depth: Mathematical Models",id:"technical-depth-mathematical-models",level:2},{value:"Forward Dynamics",id:"forward-dynamics",level:3},{value:"Inverse Dynamics",id:"inverse-dynamics",level:3},{value:"Contact Modeling",id:"contact-modeling",level:3},{value:"Practical Applications",id:"practical-applications",level:2},{value:"Development Workflow",id:"development-workflow",level:3},{value:"Training AI Systems",id:"training-ai-systems",level:3},{value:"Safety Testing",id:"safety-testing",level:3},{value:"Challenges",id:"challenges",level:2},{value:"Computational Complexity",id:"computational-complexity",level:3},{value:"Model Accuracy",id:"model-accuracy",level:3},{value:"Validation",id:"validation",level:3},{value:"Transfer Learning",id:"transfer-learning",level:3},{value:"Figure List",id:"figure-list",level:2},{value:"Code Example: Simulation Environment Implementation",id:"code-example-simulation-environment-implementation",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Summary",id:"summary-1",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.h1,{id:"chapter-13-simulation-environments",children:"Chapter 13: Simulation Environments"}),"\n",(0,s.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(e.p,{children:"This chapter explores the critical role of simulation in humanoid robotics development, covering physics simulation, major platforms, sensor simulation, and the transfer from simulation to reality. We'll examine how simulation accelerates development, enables safe testing, and supports the design of complex robotic behaviors. Understanding simulation environments is essential for efficient and effective humanoid robot development."}),"\n",(0,s.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,s.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Understand the importance of simulation in robotics development"}),"\n",(0,s.jsx)(e.li,{children:"Compare different simulation platforms and their capabilities"}),"\n",(0,s.jsx)(e.li,{children:"Implement physics and sensor simulation for humanoid robots"}),"\n",(0,s.jsx)(e.li,{children:"Address the reality gap between simulation and real-world operation"}),"\n",(0,s.jsx)(e.li,{children:"Design effective sim-to-real transfer strategies"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Physics Simulation"}),": Accurate modeling of physical interactions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Sensor Simulation"}),": Realistic simulation of robot sensors"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Simulation Platforms"}),": Gazebo, PyBullet, Webots, MuJoCo, Isaac Gym"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Reality Gap"}),": Differences between simulated and real environments"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Domain Randomization"}),": Techniques to improve sim-to-real transfer"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Digital Twins"}),": Real-time simulation models of physical systems"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"System Identification"}),": Determining model parameters from data"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"introduction-to-simulation-in-robotics",children:"Introduction to Simulation in Robotics"}),"\n",(0,s.jsx)(e.p,{children:"Simulation plays a crucial role in humanoid robotics development by providing safe, cost-effective, and rapid testing environments. Unlike physical robots, simulations allow for unlimited experimentation, failure analysis, and algorithm development without the risk of damaging expensive hardware."}),"\n",(0,s.jsx)(e.h3,{id:"benefits-of-simulation",children:"Benefits of Simulation"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Safety"}),": Test dangerous scenarios without risk to robot or humans\n",(0,s.jsx)(e.strong,{children:"Cost-Effectiveness"}),": No hardware wear, electricity costs, or maintenance\n",(0,s.jsx)(e.strong,{children:"Speed"}),": Accelerate development by running multiple experiments in parallel\n",(0,s.jsx)(e.strong,{children:"Repeatability"}),": Exact reproduction of experiments for debugging\n",(0,s.jsx)(e.strong,{children:"Control"}),": Perfect knowledge of system state for analysis\n",(0,s.jsx)(e.strong,{children:"Scalability"}),": Test on multiple virtual robots simultaneously"]}),"\n",(0,s.jsx)(e.h3,{id:"simulation-challenges",children:"Simulation Challenges"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Reality Gap"}),": Differences between simulated and real physics\n",(0,s.jsx)(e.strong,{children:"Model Fidelity"}),": Trade-offs between accuracy and computational cost\n",(0,s.jsx)(e.strong,{children:"Sensor Simulation"}),": Accurately modeling real sensor behavior\n",(0,s.jsx)(e.strong,{children:"Contact Modeling"}),": Complex interactions at contact points\n",(0,s.jsx)(e.strong,{children:"Computational Requirements"}),": High-fidelity simulation demands significant resources"]}),"\n",(0,s.jsx)(e.h2,{id:"physics-simulation-fundamentals",children:"Physics Simulation Fundamentals"}),"\n",(0,s.jsx)(e.h3,{id:"rigid-body-dynamics",children:"Rigid Body Dynamics"}),"\n",(0,s.jsx)(e.p,{children:"The fundamental equations governing rigid body motion:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Translational Motion"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"F = m * a\nv(t+dt) = v(t) + a * dt\nx(t+dt) = x(t) + v(t+dt) * dt\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Rotational Motion"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"\u03c4 = I * \u03b1\n\u03c9(t+dt) = \u03c9(t) + \u03b1 * dt\n\u03b8(t+dt) = \u03b8(t) + \u03c9(t+dt) * dt\n"})}),"\n",(0,s.jsx)(e.p,{children:"Where F is force, m is mass, a is acceleration, \u03c4 is torque, I is moment of inertia, and \u03b1 is angular acceleration."}),"\n",(0,s.jsx)(e.h3,{id:"contact-and-collision-detection",children:"Contact and Collision Detection"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Collision Detection"}),": Determine if objects intersect"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Broad Phase"}),": Fast culling of distant objects"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Narrow Phase"}),": Precise intersection testing"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Contact Response"}),": Calculate forces when objects touch"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Impulse-based"}),": Apply instantaneous impulses"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Force-based"}),": Apply continuous forces over time"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"constraint-solving",children:"Constraint Solving"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Joints"}),": Constrain relative motion between bodies"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Revolute"}),": Single rotational degree of freedom"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Prismatic"}),": Single translational degree of freedom"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Fixed"}),": No relative motion"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Spherical"}),": Ball-and-socket joint"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Solver Methods"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Sequential Impulses"}),": Iteratively resolve constraints"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Projected Gauss-Seidel"}),": Solve constraint system"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Linear Complementarity Problem (LCP)"}),": Mathematical formulation"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"major-simulation-platforms",children:"Major Simulation Platforms"}),"\n",(0,s.jsx)(e.h3,{id:"gazebo",children:"Gazebo"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Strengths"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"ROS integration"}),"\n",(0,s.jsx)(e.li,{children:"Realistic rendering"}),"\n",(0,s.jsx)(e.li,{children:"Extensive sensor models"}),"\n",(0,s.jsx)(e.li,{children:"Large model database"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Weaknesses"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Complex setup"}),"\n",(0,s.jsx)(e.li,{children:"Performance limitations"}),"\n",(0,s.jsx)(e.li,{children:"Stability issues with complex scenes"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Use Cases"}),": ROS-based development, sensor testing, navigation"]}),"\n",(0,s.jsx)(e.h3,{id:"pybullet",children:"PyBullet"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Strengths"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Python API"}),"\n",(0,s.jsx)(e.li,{children:"Fast physics engine"}),"\n",(0,s.jsx)(e.li,{children:"Good contact handling"}),"\n",(0,s.jsx)(e.li,{children:"Easy to use"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Weaknesses"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Limited rendering capabilities"}),"\n",(0,s.jsx)(e.li,{children:"Fewer built-in sensors"}),"\n",(0,s.jsx)(e.li,{children:"Less documentation"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Use Cases"}),": Reinforcement learning, physics research, rapid prototyping"]}),"\n",(0,s.jsx)(e.h3,{id:"webots",children:"Webots"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Strengths"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"User-friendly interface"}),"\n",(0,s.jsx)(e.li,{children:"Built-in controllers"}),"\n",(0,s.jsx)(e.li,{children:"Good documentation"}),"\n",(0,s.jsx)(e.li,{children:"Multi-language support"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Weaknesses"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Licensing costs"}),"\n",(0,s.jsx)(e.li,{children:"Performance with complex models"}),"\n",(0,s.jsx)(e.li,{children:"Less community support"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Use Cases"}),": Education, research, industrial applications"]}),"\n",(0,s.jsx)(e.h3,{id:"mujoco",children:"MuJoCo"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Strengths"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"High-fidelity physics"}),"\n",(0,s.jsx)(e.li,{children:"Fast simulation"}),"\n",(0,s.jsx)(e.li,{children:"Excellent contact modeling"}),"\n",(0,s.jsx)(e.li,{children:"Advanced features"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Weaknesses"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Commercial license required"}),"\n",(0,s.jsx)(e.li,{children:"Steep learning curve"}),"\n",(0,s.jsx)(e.li,{children:"Limited free version"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Use Cases"}),": Research, high-precision applications, control development"]}),"\n",(0,s.jsx)(e.h3,{id:"isaac-gym",children:"Isaac Gym"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Strengths"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"GPU-accelerated"}),"\n",(0,s.jsx)(e.li,{children:"Massive parallelization"}),"\n",(0,s.jsx)(e.li,{children:"RL optimization"}),"\n",(0,s.jsx)(e.li,{children:"High performance"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Weaknesses"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Requires NVIDIA hardware"}),"\n",(0,s.jsx)(e.li,{children:"Limited to specific use cases"}),"\n",(0,s.jsx)(e.li,{children:"Newer platform"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Use Cases"}),": Reinforcement learning, large-scale training"]}),"\n",(0,s.jsx)(e.h2,{id:"sensor-simulation",children:"Sensor Simulation"}),"\n",(0,s.jsx)(e.h3,{id:"camera-simulation",children:"Camera Simulation"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Intrinsic Parameters"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"[fx  0  cx]\n[0  fy  cy]\n[0   0   1]\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Distortion Models"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Radial"}),": k\u2081, k\u2082, k\u2083 coefficients"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Tangential"}),": p\u2081, p\u2082 coefficients"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,s.jsx)(e.p,{children:"Simulating accelerometer and gyroscope data:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Accelerometer"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"a_sim = R_world_body * (gravity + linear_acceleration) + noise\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Gyroscope"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"\u03c9_sim = angular_velocity + bias + noise\n"})}),"\n",(0,s.jsx)(e.h3,{id:"forcetorque-sensor-simulation",children:"Force/Torque Sensor Simulation"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Contact Force Calculation"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"F_contact = \u03a3 F_individual_contacts\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Noise Modeling"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Gaussian Noise"}),": Random sensor noise"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Bias Drift"}),": Slow-changing systematic errors"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Quantization"}),": Discrete sensor resolution"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"lidar-simulation",children:"LIDAR Simulation"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Ray Tracing Approach"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"for each ray:\n    distance = trace_ray(ray_direction)\n    if distance < max_range:\n        measurement = distance + noise\n    else:\n        measurement = max_range\n"})}),"\n",(0,s.jsx)(e.h2,{id:"sim-to-real-transfer",children:"Sim-to-Real Transfer"}),"\n",(0,s.jsx)(e.h3,{id:"the-reality-gap-problem",children:"The Reality Gap Problem"}),"\n",(0,s.jsx)(e.p,{children:"The performance gap between simulation and reality:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Dynamics Differences"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Mass, inertia, friction parameters"}),"\n",(0,s.jsx)(e.li,{children:"Motor dynamics and delays"}),"\n",(0,s.jsx)(e.li,{children:"Gear backlash and flexibility"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Sensor Differences"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Noise characteristics"}),"\n",(0,s.jsx)(e.li,{children:"Latency and bandwidth"}),"\n",(0,s.jsx)(e.li,{children:"Calibration differences"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Environmental Differences"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Surface properties"}),"\n",(0,s.jsx)(e.li,{children:"Lighting conditions"}),"\n",(0,s.jsx)(e.li,{children:"Air resistance"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,s.jsx)(e.p,{children:"Randomize simulation parameters to improve robustness:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Parameter_randomized = Parameter_nominal + Uniform(-\u03b5, \u03b5)\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Randomized Parameters"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Mass and inertia"}),"\n",(0,s.jsx)(e.li,{children:"Friction coefficients"}),"\n",(0,s.jsx)(e.li,{children:"Motor parameters"}),"\n",(0,s.jsx)(e.li,{children:"Sensor noise"}),"\n",(0,s.jsx)(e.li,{children:"Environmental conditions"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"system-identification",children:"System Identification"}),"\n",(0,s.jsx)(e.p,{children:"Determine real robot parameters:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Input-Output Method"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"\u03b8\u0302 = argmin_\u03b8 \u03a3(y_measured - y_simulated(\u03b8))\xb2\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Techniques"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Step response analysis"}),"\n",(0,s.jsx)(e.li,{children:"Frequency domain identification"}),"\n",(0,s.jsx)(e.li,{children:"Optimization-based methods"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"domain-adaptation",children:"Domain Adaptation"}),"\n",(0,s.jsx)(e.p,{children:"Adapt simulation to match reality:"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Model Correction"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Parameter adjustment"}),"\n",(0,s.jsx)(e.li,{children:"Disturbance modeling"}),"\n",(0,s.jsx)(e.li,{children:"Friction compensation"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Controller Adaptation"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Gain scheduling"}),"\n",(0,s.jsx)(e.li,{children:"Adaptive control"}),"\n",(0,s.jsx)(e.li,{children:"Machine learning approaches"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"technical-depth-mathematical-models",children:"Technical Depth: Mathematical Models"}),"\n",(0,s.jsx)(e.h3,{id:"forward-dynamics",children:"Forward Dynamics"}),"\n",(0,s.jsx)(e.p,{children:"Compute accelerations from forces:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"M(q)q\u0308 + C(q, q\u0307)q\u0307 + G(q) = \u03c4 + J\u1d40F_external\n"})}),"\n",(0,s.jsx)(e.p,{children:"Where M is the mass matrix, C contains Coriolis and centrifugal terms, G is gravity, \u03c4 is joint torques, and F_external is external forces."}),"\n",(0,s.jsx)(e.h3,{id:"inverse-dynamics",children:"Inverse Dynamics"}),"\n",(0,s.jsx)(e.p,{children:"Compute required torques for desired motion:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"\u03c4 = M(q)q\u0308_desired + C(q, q\u0307)q\u0307 + G(q)\n"})}),"\n",(0,s.jsx)(e.h3,{id:"contact-modeling",children:"Contact Modeling"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Spring-Damper Model"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"F_normal = k * penetration_depth + d * penetration_velocity\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Friction Cone"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"|F_friction| \u2264 \u03bc * F_normal\n"})}),"\n",(0,s.jsx)(e.h2,{id:"practical-applications",children:"Practical Applications"}),"\n",(0,s.jsx)(e.h3,{id:"development-workflow",children:"Development Workflow"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Phase 1"}),": Algorithm development in simulation\n",(0,s.jsx)(e.strong,{children:"Phase 2"}),": Controller tuning and optimization\n",(0,s.jsx)(e.strong,{children:"Phase 3"}),": Sim-to-real transfer and validation\n",(0,s.jsx)(e.strong,{children:"Phase 4"}),": Real-world testing and refinement"]}),"\n",(0,s.jsx)(e.h3,{id:"training-ai-systems",children:"Training AI Systems"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Reinforcement Learning"}),": Train policies in simulation before real deployment\n",(0,s.jsx)(e.strong,{children:"Imitation Learning"}),": Generate demonstrations in simulation\n",(0,s.jsx)(e.strong,{children:"Perception Training"}),": Create labeled datasets from simulation"]}),"\n",(0,s.jsx)(e.h3,{id:"safety-testing",children:"Safety Testing"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Failure Mode Analysis"}),": Test robot responses to various failures\n",(0,s.jsx)(e.strong,{children:"Emergency Procedures"}),": Validate safety systems\n",(0,s.jsx)(e.strong,{children:"Human Interaction"}),": Test safe interaction protocols"]}),"\n",(0,s.jsx)(e.h2,{id:"challenges",children:"Challenges"}),"\n",(0,s.jsx)(e.h3,{id:"computational-complexity",children:"Computational Complexity"}),"\n",(0,s.jsx)(e.p,{children:"High-fidelity simulation requires significant computational resources."}),"\n",(0,s.jsx)(e.h3,{id:"model-accuracy",children:"Model Accuracy"}),"\n",(0,s.jsx)(e.p,{children:"Achieving accurate models of complex real-world systems."}),"\n",(0,s.jsx)(e.h3,{id:"validation",children:"Validation"}),"\n",(0,s.jsx)(e.p,{children:"Ensuring simulation results are representative of real behavior."}),"\n",(0,s.jsx)(e.h3,{id:"transfer-learning",children:"Transfer Learning"}),"\n",(0,s.jsx)(e.p,{children:"Effectively applying simulation knowledge to real systems."}),"\n",(0,s.jsx)(e.h2,{id:"figure-list",children:"Figure List"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Figure 13.1"}),": Simulation to reality transfer pipeline"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Figure 13.2"}),": Physics simulation architecture"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Figure 13.3"}),": Sensor simulation models"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Figure 13.4"}),": Domain randomization framework"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Figure 13.5"}),": Simulation platform comparison"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"code-example-simulation-environment-implementation",children:"Code Example: Simulation Environment Implementation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport pybullet as p\nimport pybullet_data\nimport time\nimport random\nfrom typing import Dict, List, Tuple, Optional, Any\nfrom dataclasses import dataclass\nimport math\n\n@dataclass\nclass RobotState:\n    """Current state of the robot in simulation"""\n    joint_positions: np.ndarray\n    joint_velocities: np.ndarray\n    joint_torques: np.ndarray\n    base_position: np.ndarray\n    base_orientation: np.ndarray\n    base_linear_velocity: np.ndarray\n    base_angular_velocity: np.ndarray\n    timestamp: float\n\n@dataclass\nclass SimulatedSensor:\n    """Configuration for a simulated sensor"""\n    name: str\n    sensor_type: str  # \'camera\', \'imu\', \'lidar\', \'force_torque\', \'joint_position\'\n    position: np.ndarray\n    orientation: np.ndarray\n    parameters: Dict[str, Any]\n\nclass PhysicsEngine:\n    """Wrapper for physics simulation with realistic parameters"""\n\n    def __init__(self, gravity: float = -9.81, time_step: float = 0.001):\n        self.gravity = gravity\n        self.time_step = time_step\n        self.simulation_step = 0\n\n        # Connect to PyBullet\n        self.physics_client = p.connect(p.DIRECT)  # Use DIRECT for headless\n        p.setGravity(0, 0, gravity)\n        p.setTimeStep(time_step)\n\n        # Physics parameters\n        self.friction = 0.5\n        self.restitution = 0.2  # Bounciness\n        self.linear_damping = 0.04\n        self.angular_damping = 0.04\n\n    def set_gravity(self, gravity: float):\n        """Set gravity in the simulation"""\n        p.setGravity(0, 0, gravity)\n        self.gravity = gravity\n\n    def add_ground_plane(self) -> int:\n        """Add a ground plane to the simulation"""\n        return p.loadURDF("plane.urdf")\n\n    def add_robot(self, urdf_path: str, position: np.ndarray = None) -> int:\n        """Add a robot to the simulation"""\n        if position is None:\n            position = [0, 0, 1]  # Default position\n\n        robot_id = p.loadURDF(\n            urdf_path,\n            position,\n            useFixedBase=False,\n            flags=p.URDF_USE_INERTIA_FROM_FILE\n        )\n\n        # Set dynamics parameters\n        p.changeDynamics(robot_id, -1, lateralFriction=self.friction, restitution=self.restitution)\n        p.changeDynamics(robot_id, -1, linearDamping=self.linear_damping, angularDamping=self.angular_damping)\n\n        return robot_id\n\n    def step_simulation(self):\n        """Step the simulation forward by one time step"""\n        p.stepSimulation()\n        self.simulation_step += 1\n\n    def get_robot_state(self, robot_id: int) -> RobotState:\n        """Get the current state of the robot"""\n        # Get base state\n        base_pos, base_orn = p.getBasePositionAndOrientation(robot_id)\n        base_vel, base_ang_vel = p.getBaseVelocity(robot_id)\n\n        # Get joint states\n        num_joints = p.getNumJoints(robot_id)\n        joint_positions = []\n        joint_velocities = []\n        joint_torques = []\n\n        for i in range(num_joints):\n            joint_state = p.getJointState(robot_id, i)\n            joint_positions.append(joint_state[0])  # position\n            joint_velocities.append(joint_state[1])  # velocity\n            joint_torques.append(joint_state[3])    # applied torque\n\n        return RobotState(\n            joint_positions=np.array(joint_positions),\n            joint_velocities=np.array(joint_velocities),\n            joint_torques=np.array(joint_torques),\n            base_position=np.array(base_pos),\n            base_orientation=np.array(base_orn),\n            base_linear_velocity=np.array(base_vel),\n            base_angular_velocity=np.array(base_ang_vel),\n            timestamp=self.simulation_step * self.time_step\n        )\n\n    def apply_torques(self, robot_id: int, torques: np.ndarray):\n        """Apply torques to robot joints"""\n        num_joints = min(len(torques), p.getNumJoints(robot_id))\n\n        # Apply torques using torque control\n        for i in range(num_joints):\n            p.setJointMotorControl2(\n                bodyIndex=robot_id,\n                jointIndex=i,\n                controlMode=p.TORQUE_CONTROL,\n                force=torques[i]\n            )\n\n    def apply_position_commands(self, robot_id: int, positions: np.ndarray, forces: Optional[np.ndarray] = None):\n        """Apply position commands to robot joints"""\n        num_joints = min(len(positions), p.getNumJoints(robot_id))\n\n        if forces is None:\n            forces = [500] * num_joints  # Default maximum forces\n\n        for i in range(num_joints):\n            p.setJointMotorControl2(\n                bodyIndex=robot_id,\n                jointIndex=i,\n                controlMode=p.POSITION_CONTROL,\n                targetPosition=positions[i],\n                force=forces[i]\n            )\n\nclass SimulatedSensorSystem:\n    """System for simulating various robot sensors"""\n\n    def __init__(self, physics_engine: PhysicsEngine):\n        self.physics_engine = physics_engine\n        self.sensors: List[SimulatedSensor] = []\n        self.sensor_data: Dict[str, Any] = {}\n\n    def add_camera_sensor(self, name: str, position: np.ndarray, orientation: np.ndarray,\n                         width: int = 640, height: int = 480, fov: float = 60.0) -> str:\n        """Add a camera sensor to the simulation"""\n        sensor = SimulatedSensor(\n            name=name,\n            sensor_type=\'camera\',\n            position=position,\n            orientation=orientation,\n            parameters={\n                \'width\': width,\n                \'height\': height,\n                \'fov\': fov,\n                \'aspect\': width / height,\n                \'near_plane\': 0.01,\n                \'far_plane\': 100.0\n            }\n        )\n        self.sensors.append(sensor)\n        return name\n\n    def add_imu_sensor(self, name: str, position: np.ndarray, orientation: np.ndarray,\n                      noise_std: Dict[str, float] = None) -> str:\n        """Add an IMU sensor to the simulation"""\n        if noise_std is None:\n            noise_std = {\n                \'accel\': 0.01,\n                \'gyro\': 0.001,\n                \'mag\': 0.1\n            }\n\n        sensor = SimulatedSensor(\n            name=name,\n            sensor_type=\'imu\',\n            position=position,\n            orientation=orientation,\n            parameters={\n                \'noise_std\': noise_std,\n                \'update_rate\': 100.0  # Hz\n            }\n        )\n        self.sensors.append(sensor)\n        return name\n\n    def add_lidar_sensor(self, name: str, position: np.ndarray, orientation: np.ndarray,\n                        num_rays: int = 720, fov: float = 2 * math.pi) -> str:\n        """Add a LIDAR sensor to the simulation"""\n        sensor = SimulatedSensor(\n            name=name,\n            sensor_type=\'lidar\',\n            position=position,\n            orientation=orientation,\n            parameters={\n                \'num_rays\': num_rays,\n                \'fov\': fov,\n                \'min_range\': 0.1,\n                \'max_range\': 10.0,\n                \'noise_std\': 0.01\n            }\n        )\n        self.sensors.append(sensor)\n        return name\n\n    def simulate_camera(self, sensor: SimulatedSensor, robot_state: RobotState) -> Dict[str, Any]:\n        """Simulate camera sensor data"""\n        # Calculate camera position and orientation\n        # In a real implementation, this would render the scene\n        # For this example, we\'ll return simulated data\n\n        width = sensor.parameters[\'width\']\n        height = sensor.parameters[\'height\']\n\n        # Simulate image data (in reality, this would be a rendered image)\n        image = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)\n\n        # Add some "features" to make it more realistic\n        for _ in range(10):\n            x = random.randint(0, width-1)\n            y = random.randint(0, height-1)\n            size = random.randint(5, 20)\n            color = [random.randint(0, 255) for _ in range(3)]\n            cv2 = __import__(\'cv2\')\n            cv2.circle(image, (x, y), size, color, -1)\n\n        return {\n            \'image\': image,\n            \'timestamp\': robot_state.timestamp,\n            \'width\': width,\n            \'height\': height\n        }\n\n    def simulate_imu(self, sensor: SimulatedSensor, robot_state: RobotState) -> Dict[str, Any]:\n        """Simulate IMU sensor data"""\n        # Get robot\'s actual state\n        # In a real implementation, this would account for sensor mounting position\n\n        # Simulate accelerometer (gravity + linear acceleration)\n        gravity_vector = np.array([0, 0, self.physics_engine.gravity])\n        linear_acc = robot_state.base_linear_velocity / self.physics_engine.time_step\n        accel = gravity_vector + linear_acc\n\n        # Add noise\n        noise_std = sensor.parameters[\'noise_std\']\n        accel += np.random.normal(0, noise_std[\'accel\'], 3)\n\n        # Simulate gyroscope\n        gyro = robot_state.base_angular_velocity + np.random.normal(0, noise_std[\'gyro\'], 3)\n\n        # Simulate magnetometer (simplified)\n        mag = np.array([0.2, 0.0, 0.4]) + np.random.normal(0, noise_std[\'mag\'], 3)\n\n        return {\n            \'accelerometer\': accel,\n            \'gyroscope\': gyro,\n            \'magnetometer\': mag,\n            \'timestamp\': robot_state.timestamp\n        }\n\n    def simulate_lidar(self, sensor: SimulatedSensor, robot_state: RobotState) -> Dict[str, Any]:\n        """Simulate LIDAR sensor data"""\n        num_rays = sensor.parameters[\'num_rays\']\n        fov = sensor.parameters[\'fov\']\n        max_range = sensor.parameters[\'max_range\']\n        noise_std = sensor.parameters[\'noise_std\']\n\n        # Simulate distance measurements\n        # In a real implementation, this would trace rays in the scene\n        distances = []\n\n        for i in range(num_rays):\n            # Simulate a distance with some variation\n            base_distance = max_range * (0.5 + 0.3 * math.sin(i * fov / num_rays))\n            distance = base_distance + random.gauss(0, noise_std)\n            distance = max(sensor.parameters[\'min_range\'], min(max_range, distance))\n            distances.append(distance)\n\n        return {\n            \'ranges\': np.array(distances),\n            \'min_range\': sensor.parameters[\'min_range\'],\n            \'max_range\': max_range,\n            \'fov\': fov,\n            \'timestamp\': robot_state.timestamp\n        }\n\n    def get_sensor_data(self, robot_state: RobotState) -> Dict[str, Any]:\n        """Get data from all simulated sensors"""\n        sensor_data = {}\n\n        for sensor in self.sensors:\n            if sensor.sensor_type == \'camera\':\n                sensor_data[sensor.name] = self.simulate_camera(sensor, robot_state)\n            elif sensor.sensor_type == \'imu\':\n                sensor_data[sensor.name] = self.simulate_imu(sensor, robot_state)\n            elif sensor.sensor_type == \'lidar\':\n                sensor_data[sensor.name] = self.simulate_lidar(sensor, robot_state)\n\n        return sensor_data\n\nclass SimulationEnvironment:\n    """Complete simulation environment for humanoid robots"""\n\n    def __init__(self, gravity: float = -9.81, time_step: float = 0.001):\n        self.physics_engine = PhysicsEngine(gravity, time_step)\n        self.sensor_system = SimulatedSensorSystem(self.physics_engine)\n        self.robot_id = None\n        self.is_running = False\n\n    def load_robot(self, urdf_path: str, position: np.ndarray = None) -> int:\n        """Load a robot model into the simulation"""\n        self.robot_id = self.physics_engine.add_robot(urdf_path, position)\n        return self.robot_id\n\n    def add_ground(self):\n        """Add a ground plane to the simulation"""\n        return self.physics_engine.add_ground_plane()\n\n    def add_sensor(self, sensor_type: str, name: str, position: np.ndarray,\n                   orientation: np.ndarray, **kwargs) -> str:\n        """Add a sensor to the robot"""\n        if sensor_type == \'camera\':\n            return self.sensor_system.add_camera_sensor(name, position, orientation, **kwargs)\n        elif sensor_type == \'imu\':\n            return self.sensor_system.add_imu_sensor(name, position, orientation, **kwargs)\n        elif sensor_type == \'lidar\':\n            return self.sensor_system.add_lidar_sensor(name, position, orientation, **kwargs)\n        else:\n            raise ValueError(f"Unknown sensor type: {sensor_type}")\n\n    def get_robot_state(self) -> RobotState:\n        """Get the current robot state"""\n        if self.robot_id is None:\n            raise RuntimeError("No robot loaded in simulation")\n        return self.physics_engine.get_robot_state(self.robot_id)\n\n    def apply_torques(self, torques: np.ndarray):\n        """Apply torques to robot joints"""\n        if self.robot_id is None:\n            raise RuntimeError("No robot loaded in simulation")\n        self.physics_engine.apply_torques(self.robot_id, torques)\n\n    def apply_position_commands(self, positions: np.ndarray, forces: Optional[np.ndarray] = None):\n        """Apply position commands to robot joints"""\n        if self.robot_id is None:\n            raise RuntimeError("No robot loaded in simulation")\n        self.physics_engine.apply_position_commands(self.robot_id, positions, forces)\n\n    def step(self) -> Tuple[RobotState, Dict[str, Any]]:\n        """Step the simulation and return state and sensor data"""\n        self.physics_engine.step_simulation()\n        state = self.get_robot_state()\n        sensor_data = self.sensor_system.get_sensor_data(state)\n        return state, sensor_data\n\n    def run_simulation(self, steps: int, control_callback=None):\n        """Run the simulation for a specified number of steps"""\n        self.is_running = True\n        states = []\n        sensor_data_list = []\n\n        for step in range(steps):\n            state, sensor_data = self.step()\n            states.append(state)\n            sensor_data_list.append(sensor_data)\n\n            # Apply control if callback provided\n            if control_callback:\n                torques = control_callback(state, sensor_data)\n                if torques is not None:\n                    self.apply_torques(torques)\n\n        self.is_running = False\n        return states, sensor_data_list\n\ndef demonstrate_simulation():\n    """Demonstrate simulation concepts and capabilities"""\n    print("Simulation Environments - Chapter 13")\n    print("=" * 45)\n\n    # Initialize simulation environment\n    print("1. Initializing Simulation Environment:")\n    sim_env = SimulationEnvironment(gravity=-9.81, time_step=0.001)\n    sim_env.add_ground()\n    print("   - Physics engine initialized with gravity -9.81 m/s\xb2")\n    print("   - Time step: 0.001s (1000 Hz)")\n    print("   - Ground plane added")\n\n    # Note: We can\'t load a specific humanoid URDF without one available\n    # Instead, we\'ll use a simple model for demonstration\n    print("\\n2. Loading Robot Model:")\n    try:\n        # Use a simple model from PyBullet\'s data\n        sim_env.load_robot("r2d2.urdf", position=[0, 0, 1])\n        print("   - Robot loaded successfully")\n    except:\n        print("   - Using simple model for demonstration")\n        # Create a simple box as a placeholder\n        sim_env.robot_id = p.loadURDF("r2d2.urdf", [0, 0, 1]) if p.getNumBodies() == 1 else p.loadURDF("cube.urdf", [0, 0, 1])\n\n    # Add sensors\n    print("\\n3. Adding Sensors:")\n    camera_id = sim_env.add_sensor(\n        \'camera\', \'main_camera\',\n        position=np.array([0.1, 0, 0.1]),\n        orientation=np.array([0, 0, 0, 1]),\n        width=320, height=240, fov=60\n    )\n    print(f"   - Camera sensor added: {camera_id}")\n\n    imu_id = sim_env.add_sensor(\n        \'imu\', \'imu_sensor\',\n        position=np.array([0, 0, 0.5]),\n        orientation=np.array([0, 0, 0, 1])\n    )\n    print(f"   - IMU sensor added: {imu_id}")\n\n    lidar_id = sim_env.add_sensor(\n        \'lidar\', \'lidar_sensor\',\n        position=np.array([0.2, 0, 0.5]),\n        orientation=np.array([0, 0, 0, 1]),\n        num_rays=360, fov=2*math.pi\n    )\n    print(f"   - LIDAR sensor added: {lidar_id}")\n\n    # Get initial state\n    print("\\n4. Initial Robot State:")\n    initial_state = sim_env.get_robot_state()\n    print(f"   - Position: [{initial_state.base_position[0]:.3f}, {initial_state.base_position[1]:.3f}, {initial_state.base_position[2]:.3f}]")\n    print(f"   - Orientation: [{initial_state.base_orientation[0]:.3f}, {initial_state.base_orientation[1]:.3f}, {initial_state.base_orientation[2]:.3f}, {initial_state.base_orientation[3]:.3f}]")\n    print(f"   - Joint positions shape: {initial_state.joint_positions.shape}")\n    print(f"   - Joint velocities shape: {initial_state.joint_velocities.shape}")\n\n    # Run a short simulation\n    print("\\n5. Running Simulation:")\n    print("   - Executing 1000 steps (1 second at 1000 Hz)")\n\n    def simple_control_callback(state: RobotState, sensor_data: Dict[str, Any]):\n        """Simple control callback for demonstration"""\n        # Apply small random torques to joints\n        if len(state.joint_positions) > 0:\n            torques = np.random.uniform(-0.1, 0.1, len(state.joint_positions))\n            return torques\n        return None\n\n    states, sensor_data_list = sim_env.run_simulation(1000, simple_control_callback)\n\n    final_state = states[-1]\n    final_sensor_data = sensor_data_list[-1]\n\n    print(f"   - Final position: [{final_state.base_position[0]:.3f}, {final_state.base_position[1]:.3f}, {final_state.base_position[2]:.3f}]")\n    print(f"   - Position change: {np.linalg.norm(final_state.base_position - initial_state.base_position):.3f}m")\n\n    # Analyze sensor data\n    print("\\n6. Sensor Data Analysis:")\n    if \'main_camera\' in final_sensor_data:\n        camera_data = final_sensor_data[\'main_camera\']\n        print(f"   - Camera: {camera_data[\'width\']}x{camera_data[\'height\']} image captured")\n\n    if \'imu_sensor\' in final_sensor_data:\n        imu_data = final_sensor_data[\'imu_sensor\']\n        print(f"   - IMU: Accelerometer [{imu_data[\'accelerometer\'][0]:.3f}, {imu_data[\'accelerometer\'][1]:.3f}, {imu_data[\'accelerometer\'][2]:.3f}]")\n        print(f"   - IMU: Gyroscope [{imu_data[\'gyroscope\'][0]:.3f}, {imu_data[\'gyroscope\'][1]:.3f}, {imu_data[\'gyroscope\'][2]:.3f}]")\n\n    if \'lidar_sensor\' in final_sensor_data:\n        lidar_data = final_sensor_data[\'lidar_sensor\']\n        avg_distance = np.mean(lidar_data[\'ranges\'])\n        print(f"   - LIDAR: {len(lidar_data[\'ranges\'])} rays, avg distance: {avg_distance:.3f}m")\n\n    # Demonstrate physics properties\n    print("\\n7. Physics Simulation Properties:")\n    print(f"   - Gravity: {sim_env.physics_engine.gravity} m/s\xb2")\n    print(f"   - Time step: {sim_env.physics_engine.time_step}s")\n    print(f"   - Friction coefficient: {sim_env.physics_engine.friction}")\n    print(f"   - Restitution (bounciness): {sim_env.physics_engine.restitution}")\n\n    # Performance metrics\n    print("\\n8. Performance Analysis:")\n    simulation_time = len(states) * sim_env.physics_engine.time_step\n    print(f"   - Simulated time: {simulation_time:.3f}s")\n    print(f"   - Real time: {(time.time() - time.time()) + 0.1:.3f}s (approximate)")  # Placeholder for actual timing\n    print(f"   - Simulation speed: Real-time (1x) at 1000 Hz")\n\n    # Domain randomization example\n    print("\\n9. Domain Randomization Example:")\n    print("   - Mass variation: \xb110% of nominal values")\n    print("   - Friction variation: Uniform(0.3, 0.7)")\n    print("   - Motor parameter variation: \xb15% of nominal")\n    print("   - Sensor noise: Gaussian with varying std dev")\n\n    # Reality gap mitigation\n    print("\\n10. Reality Gap Mitigation Strategies:")\n    print("    - System identification for parameter tuning")\n    print("    - Domain randomization for robustness")\n    print("    - Sim-to-real transfer learning")\n    print("    - Sensor noise modeling")\n    print("    - Contact parameter adjustment")\n\n    # Simulation platforms comparison\n    print("\\n11. Simulation Platform Comparison:")\n    platforms = {\n        "PyBullet": {\n            "Pros": ["Free", "Fast", "Python API", "Good for RL"],\n            "Cons": ["Basic rendering", "Limited sensors"],\n            "Best For": "RL, rapid prototyping"\n        },\n        "Gazebo": {\n            "Pros": ["Realistic rendering", "ROS integration", "Rich sensor models"],\n            "Cons": ["Complex setup", "Performance issues"],\n            "Best For": "ROS development, navigation"\n        },\n        "Webots": {\n            "Pros": ["User-friendly", "Built-in controllers", "Good docs"],\n            "Cons": ["Licensing costs", "Limited community"],\n            "Best For": "Education, research"\n        },\n        "MuJoCo": {\n            "Pros": ["High-fidelity", "Fast", "Excellent contacts"],\n            "Cons": ["Commercial", "Steep learning curve"],\n            "Best For": "Research, precision control"\n        }\n    }\n\n    for platform, details in platforms.items():\n        print(f"\\n    {platform}:")\n        print(f"      Pros: {\', \'.join(details[\'Pros\'])}")\n        print(f"      Cons: {\', \'.join(details[\'Cons\'])}")\n        print(f"      Best For: {details[\'Best For\']}")\n\n    return {\n        \'states_count\': len(states),\n        \'sensors_count\': len(sim_env.sensor_system.sensors),\n        \'simulation_time\': simulation_time,\n        \'position_change\': np.linalg.norm(final_state.base_position - initial_state.base_position)\n    }\n\ndef analyze_simulation_performance(results: Dict) -> Dict:\n    """Analyze simulation performance metrics"""\n    analysis = {\n        \'simulation_efficiency\': {\n            \'steps_per_second\': results[\'states_count\'] / max(results[\'simulation_time\'], 1),\n            \'sensors_active\': results[\'sensors_count\'],\n            \'realism_score\': \'N/A\'  # Would require detailed comparison with real robot\n        },\n        \'physics_accuracy\': {\n            \'position_drift\': results[\'position_change\'],\n            \'expected_behavior\': \'Robot should remain relatively stable with random torques\'\n        },\n        \'computational_performance\': {\n            \'estimated_cpu_usage\': \'Low for simple simulation\',\n            \'scalability\': \'Can run multiple instances in parallel\'\n        }\n    }\n\n    return analysis\n\ndef discuss_sim_to_real_transfer():\n    """Discuss sim-to-real transfer challenges and solutions"""\n    print(f"\\n12. Sim-to-Real Transfer Challenges and Solutions:")\n\n    challenges = [\n        ("Dynamics Mismatch", "Real robot has different mass, friction, and motor characteristics"),\n        ("Sensor Differences", "Simulated sensors don\'t perfectly match real sensors"),\n        ("Environmental Factors", "Lighting, surface properties, air resistance differ"),\n        ("Modeling Limitations", "Simulation can\'t capture all real-world complexities")\n    ]\n\n    print("\\n    Key Challenges:")\n    for challenge, description in challenges:\n        print(f"      - {challenge}: {description}")\n\n    solutions = [\n        ("System Identification", "Measure and tune real robot parameters"),\n        ("Domain Randomization", "Train in varied simulation conditions"),\n        ("Domain Adaptation", "Adapt simulation to match reality"),\n        ("Progressive Transfer", "Gradually move from sim to real"),\n        ("Robust Control", "Design controllers that handle uncertainty")\n    ]\n\n    print("\\n    Solutions:")\n    for solution, description in solutions:\n        print(f"      - {solution}: {description}")\n\n    best_practices = [\n        "Start with simple tasks in simulation",\n        "Validate simulation models against real data",\n        "Use robust control methods",\n        "Implement safety measures for real testing",\n        "Iterate between sim and real testing"\n    ]\n\n    print("\\n    Best Practices:")\n    for practice in best_practices:\n        print(f"      - {practice}")\n\nif __name__ == "__main__":\n    # Import cv2 locally for the camera simulation\n    try:\n        import cv2\n    except ImportError:\n        print("OpenCV not available, using numpy arrays for camera simulation")\n\n    # Run the demonstration\n    results = demonstrate_simulation()\n\n    # Analyze performance\n    performance_analysis = analyze_simulation_performance(results)\n\n    print(f"\\n13. Performance Analysis Summary:")\n    for category, metrics in performance_analysis.items():\n        print(f"\\n   {category.replace(\'_\', \' \').title()}:")\n        for metric, value in metrics.items():\n            print(f"     - {metric.replace(\'_\', \' \')}: {value}")\n\n    # Discuss sim-to-real transfer\n    discuss_sim_to_real_transfer()\n\n    print(f"\\n14. Key Takeaways:")\n    print("    - Simulation accelerates development and reduces costs")\n    print("    - Multiple physics engines offer different trade-offs")\n    print("    - Sensor simulation must account for real-world noise")\n    print("    - Domain randomization improves sim-to-real transfer")\n    print("    - Reality gap remains a significant challenge")\n\n    print(f"\\nSimulation Environments - Chapter 13 Complete!")\n\n    # Disconnect from physics engine\n    try:\n        p.disconnect()\n    except:\n        pass\n'})}),"\n",(0,s.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:"Implement a physics simulation with realistic contact dynamics for a humanoid robot walking."}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:"Design a sensor simulation system that accurately models the noise characteristics of real IMU sensors."}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:"Create a domain randomization framework that improves sim-to-real transfer for a manipulation task."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"summary-1",children:"Summary"}),"\n",(0,s.jsx)(e.p,{children:"This chapter provided a comprehensive overview of simulation environments for humanoid robotics, covering physics simulation, sensor modeling, and sim-to-real transfer strategies. We explored major simulation platforms, technical implementation details, and the challenges of bridging the reality gap. The concepts and code examples presented will help in developing effective simulation environments that accelerate humanoid robot development while maintaining accuracy and reliability."})]})}function m(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(c,{...n})}):c(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>a,x:()=>o});var s=i(6540);const t={},r=s.createContext(t);function a(n){const e=s.useContext(r);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:a(n.components),s.createElement(r.Provider,{value:e},n.children)}}}]);