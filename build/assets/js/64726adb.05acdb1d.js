"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[159],{7401:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>c});var t=i(4848),o=i(8453);const a={sidebar_position:1},r="Chapter 7: Motion Planning and Locomotion",s={id:"modules/module-3-control/chapter-7-motion-planning",title:"Chapter 7: Motion Planning and Locomotion",description:"Summary",source:"@site/docs/modules/module-3-control/chapter-7-motion-planning.md",sourceDirName:"modules/module-3-control",slug:"/modules/module-3-control/chapter-7-motion-planning",permalink:"/docs/modules/module-3-control/chapter-7-motion-planning",draft:!1,unlisted:!1,editUrl:"https://github.com/Mehwish-Malik/AI-Robotics-Book.git/docs/modules/module-3-control/chapter-7-motion-planning.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Chapter 6: Control Systems and Electronics",permalink:"/docs/modules/module-2-hardware/chapter-6-control-systems"},next:{title:"Chapter 8: Locomotion and Gait Control",permalink:"/docs/modules/module-3-control/chapter-8-locomotion"}},l={},c=[{value:"Summary",id:"summary",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Introduction to Motion Planning",id:"introduction-to-motion-planning",level:2},{value:"Motion Planning Challenges",id:"motion-planning-challenges",level:3},{value:"Motion Planning Framework",id:"motion-planning-framework",level:3},{value:"Configuration Space and Representation",id:"configuration-space-and-representation",level:2},{value:"Configuration Space (C-space)",id:"configuration-space-c-space",level:3},{value:"Free Space vs. Obstacle Space",id:"free-space-vs-obstacle-space",level:3},{value:"Kinematic Constraints",id:"kinematic-constraints",level:3},{value:"Motion Planning Algorithms",id:"motion-planning-algorithms",level:2},{value:"Sampling-based Algorithms",id:"sampling-based-algorithms",level:3},{value:"Grid-based Algorithms",id:"grid-based-algorithms",level:3},{value:"Optimization-based Algorithms",id:"optimization-based-algorithms",level:3},{value:"Trajectory Generation and Optimization",id:"trajectory-generation-and-optimization",level:2},{value:"Path vs. Trajectory",id:"path-vs-trajectory",level:3},{value:"Trajectory Representation",id:"trajectory-representation",level:3},{value:"Time-Optimal Trajectory Generation",id:"time-optimal-trajectory-generation",level:3},{value:"Velocity and Acceleration Profiles",id:"velocity-and-acceleration-profiles",level:3},{value:"Obstacle Avoidance",id:"obstacle-avoidance",level:2},{value:"Static Obstacle Avoidance",id:"static-obstacle-avoidance",level:3},{value:"Dynamic Obstacle Avoidance",id:"dynamic-obstacle-avoidance",level:3},{value:"Local Replanning",id:"local-replanning",level:3},{value:"Bipedal Locomotion Planning",id:"bipedal-locomotion-planning",level:2},{value:"Walking Pattern Generation",id:"walking-pattern-generation",level:3},{value:"Zero Moment Point (ZMP) Planning",id:"zero-moment-point-zmp-planning",level:3},{value:"Capture Point Planning",id:"capture-point-planning",level:3},{value:"Technical Depth: Mathematical Foundations",id:"technical-depth-mathematical-foundations",level:2},{value:"Configuration Space Formulation",id:"configuration-space-formulation",level:3},{value:"Collision Detection",id:"collision-detection",level:3},{value:"Optimization Formulation",id:"optimization-formulation",level:3},{value:"Practical Applications",id:"practical-applications",level:2},{value:"Navigation in Human Environments",id:"navigation-in-human-environments",level:3},{value:"Manipulation Motion Planning",id:"manipulation-motion-planning",level:3},{value:"Multi-modal Locomotion",id:"multi-modal-locomotion",level:3},{value:"Challenges",id:"challenges",level:2},{value:"Computational Complexity",id:"computational-complexity",level:3},{value:"Real-time Performance",id:"real-time-performance",level:3},{value:"Uncertainty Handling",id:"uncertainty-handling",level:3},{value:"Dynamic Environments",id:"dynamic-environments",level:3},{value:"Figure List",id:"figure-list",level:2},{value:"Code Example: Motion Planning Implementation",id:"code-example-motion-planning-implementation",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Summary",id:"summary-1",level:2}];function d(n){const e={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"chapter-7-motion-planning-and-locomotion",children:"Chapter 7: Motion Planning and Locomotion"}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"This chapter explores the fundamental concepts of motion planning for humanoid robots, focusing on how these complex systems navigate space and execute purposeful movements. We'll examine various motion planning algorithms, trajectory generation techniques, and the unique challenges of planning for bipedal locomotion. Understanding motion planning is crucial for developing robots that can move efficiently and safely in complex environments."}),"\n",(0,t.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Understand the principles of motion planning for humanoid robots"}),"\n",(0,t.jsx)(e.li,{children:"Analyze different motion planning algorithms and their applications"}),"\n",(0,t.jsx)(e.li,{children:"Generate trajectories for complex humanoid movements"}),"\n",(0,t.jsx)(e.li,{children:"Implement obstacle avoidance strategies"}),"\n",(0,t.jsx)(e.li,{children:"Evaluate motion planning performance in dynamic environments"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Configuration Space (C-space)"}),": The space of all possible robot configurations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Motion Planning"}),": Finding a collision-free path from start to goal"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Trajectory Generation"}),": Creating time-parameterized paths with velocity and acceleration profiles"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Kinodynamic Planning"}),": Planning that considers both kinematic and dynamic constraints"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sampling-based Algorithms"}),": Algorithms that sample the configuration space"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Optimization-based Planning"}),": Formulating planning as an optimization problem"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Anytime Algorithms"}),": Algorithms that can return valid solutions at any time"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"introduction-to-motion-planning",children:"Introduction to Motion Planning"}),"\n",(0,t.jsx)(e.p,{children:"Motion planning for humanoid robots is significantly more complex than for simpler robots due to their high degrees of freedom and the need to maintain balance during movement. Unlike wheeled robots that operate in 2D space, humanoid robots must plan in high-dimensional configuration spaces while considering balance, obstacle avoidance, and dynamic constraints."}),"\n",(0,t.jsx)(e.h3,{id:"motion-planning-challenges",children:"Motion Planning Challenges"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"High Dimensionality"}),": Humanoid robots typically have 30+ degrees of freedom, creating enormous configuration spaces."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Balance Constraints"}),": The robot must maintain stability throughout the motion, limiting feasible configurations."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Dynamic Constraints"}),": Acceleration and velocity limits must be respected to prevent damage and maintain stability."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Real-time Requirements"}),": Many applications require motion planning to be computed in real-time."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Environmental Complexity"}),": Real-world environments are dynamic and partially observable."]}),"\n",(0,t.jsx)(e.h3,{id:"motion-planning-framework",children:"Motion Planning Framework"}),"\n",(0,t.jsx)(e.p,{children:"The motion planning process typically involves:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Problem Formulation"}),": Define start state, goal state, and constraints"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Space Representation"}),": Represent the configuration space and obstacles"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Planning Algorithm"}),": Apply algorithm to find a feasible path"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Trajectory Generation"}),": Convert path to time-parameterized trajectory"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Execution and Monitoring"}),": Execute trajectory and handle deviations"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"configuration-space-and-representation",children:"Configuration Space and Representation"}),"\n",(0,t.jsx)(e.h3,{id:"configuration-space-c-space",children:"Configuration Space (C-space)"}),"\n",(0,t.jsx)(e.p,{children:"For a humanoid robot, the configuration space is the set of all possible joint angles:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"q = [q\u2081, q\u2082, ..., q\u2099]\n"})}),"\n",(0,t.jsx)(e.p,{children:"Where n is the number of degrees of freedom. The dimensionality of C-space makes planning computationally intensive."}),"\n",(0,t.jsx)(e.h3,{id:"free-space-vs-obstacle-space",children:"Free Space vs. Obstacle Space"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Free Space (C_free)"}),": Configurations where the robot does not collide with obstacles\n",(0,t.jsx)(e.strong,{children:"Obstacle Space (C_obs)"}),": Configurations where the robot collides with obstacles\n",(0,t.jsx)(e.strong,{children:"C_free = C_total - C_obs"})]}),"\n",(0,t.jsx)(e.h3,{id:"kinematic-constraints",children:"Kinematic Constraints"}),"\n",(0,t.jsx)(e.p,{children:"Humanoid robots have various kinematic constraints:"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Joint Limits"}),": Each joint has physical limits"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"q_min \u2264 q \u2264 q_max\n"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Holonomic Constraints"}),": Constraints that can be expressed as functions of position\n",(0,t.jsx)(e.strong,{children:"Non-holonomic Constraints"}),": Constraints that depend on velocity and cannot be integrated to position constraints"]}),"\n",(0,t.jsx)(e.h2,{id:"motion-planning-algorithms",children:"Motion Planning Algorithms"}),"\n",(0,t.jsx)(e.h3,{id:"sampling-based-algorithms",children:"Sampling-based Algorithms"}),"\n",(0,t.jsx)(e.p,{children:"Sampling-based algorithms explore the configuration space by randomly sampling configurations and connecting them to form a graph or tree."}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Probabilistic Roadmap (PRM)"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Pre-compute roadmap of the environment"}),"\n",(0,t.jsx)(e.li,{children:"Query-specific planning using the roadmap"}),"\n",(0,t.jsx)(e.li,{children:"Good for multiple queries in static environments"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Rapidly-exploring Random Trees (RRT)"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Grow tree from start configuration"}),"\n",(0,t.jsx)(e.li,{children:"Random sampling guides exploration"}),"\n",(0,t.jsx)(e.li,{children:"Good for single-query problems"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"RRT"}),"* (RRT-star):"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Asymptotically optimal version of RRT"}),"\n",(0,t.jsx)(e.li,{children:"Rewires tree to improve solution quality"}),"\n",(0,t.jsx)(e.li,{children:"Balances exploration and optimization"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"grid-based-algorithms",children:"Grid-based Algorithms"}),"\n",(0,t.jsx)(e.p,{children:"Grid-based methods discretize the configuration space into a grid:"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsxs)(e.em,{children:[(0,t.jsx)(e.em,{children:"A"})," Algorithm"]}),"*:"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Heuristic search algorithm"}),"\n",(0,t.jsx)(e.li,{children:"Guarantees optimal solution"}),"\n",(0,t.jsx)(e.li,{children:"Memory usage grows exponentially with dimensionality"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Dijkstra's Algorithm"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Explores outward from start"}),"\n",(0,t.jsx)(e.li,{children:"Guarantees optimal solution"}),"\n",(0,t.jsx)(e.li,{children:"No heuristic guidance"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"optimization-based-algorithms",children:"Optimization-based Algorithms"}),"\n",(0,t.jsx)(e.p,{children:"Formulate planning as an optimization problem:"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"CHOMP (Covariant Hamiltonian Optimization for Motion Planning)"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Trajectory optimization approach"}),"\n",(0,t.jsx)(e.li,{children:"Uses covariant gradient to handle constraints"}),"\n",(0,t.jsx)(e.li,{children:"Good for high-DOF systems"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"STOMP (Stochastic Trajectory Optimization)"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Random sampling and optimization"}),"\n",(0,t.jsx)(e.li,{children:"Handles complex cost functions"}),"\n",(0,t.jsx)(e.li,{children:"Robust to local minima"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"trajectory-generation-and-optimization",children:"Trajectory Generation and Optimization"}),"\n",(0,t.jsx)(e.h3,{id:"path-vs-trajectory",children:"Path vs. Trajectory"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Path"}),": Geometric route through configuration space\n",(0,t.jsx)(e.strong,{children:"Trajectory"}),": Time-parameterized path with velocity and acceleration profiles"]}),"\n",(0,t.jsx)(e.h3,{id:"trajectory-representation",children:"Trajectory Representation"}),"\n",(0,t.jsx)(e.p,{children:"Trajectories can be represented as:"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Polynomial Trajectories"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"q(t) = a\u2080 + a\u2081t + a\u2082t\xb2 + a\u2083t\xb3 + ...\n"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Spline Trajectories"}),": Piecewise polynomial curves\n",(0,t.jsx)(e.strong,{children:"B\xe9zier Curves"}),": Parametric curves defined by control points"]}),"\n",(0,t.jsx)(e.h3,{id:"time-optimal-trajectory-generation",children:"Time-Optimal Trajectory Generation"}),"\n",(0,t.jsx)(e.p,{children:"Minimize execution time while respecting constraints:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"min \u222b\u2080\u1d40 dt\ns.t. q(t) \u2208 C_free \u2200t \u2208 [0,T]\n     |q\u0307(t)| \u2264 v_max\n     |q\u0308(t)| \u2264 a_max\n"})}),"\n",(0,t.jsx)(e.h3,{id:"velocity-and-acceleration-profiles",children:"Velocity and Acceleration Profiles"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Trapezoidal Profile"}),": Constant acceleration, constant velocity, constant deceleration\n",(0,t.jsx)(e.strong,{children:"S-curve Profile"}),": Smooth acceleration/deceleration profiles for reduced jerk\n",(0,t.jsx)(e.strong,{children:"Minimum Jerk Profile"}),": Minimize jerk (third derivative) for smooth motion"]}),"\n",(0,t.jsx)(e.h2,{id:"obstacle-avoidance",children:"Obstacle Avoidance"}),"\n",(0,t.jsx)(e.h3,{id:"static-obstacle-avoidance",children:"Static Obstacle Avoidance"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Configuration Space Obstacles"}),": Transform workspace obstacles to C-space\n",(0,t.jsx)(e.strong,{children:"Distance Fields"}),": Pre-computed distance to nearest obstacle\n",(0,t.jsx)(e.strong,{children:"Collision Detection"}),": Real-time collision checking algorithms"]}),"\n",(0,t.jsx)(e.h3,{id:"dynamic-obstacle-avoidance",children:"Dynamic Obstacle Avoidance"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Velocity Obstacles"}),": Regions in velocity space that lead to collision\n",(0,t.jsx)(e.strong,{children:"Reciprocal Velocity Obstacles (RVO)"}),": Consider other agents' responses\n",(0,t.jsx)(e.strong,{children:"Optimal Reciprocal Collision Avoidance (ORCA)"}),": Linear constraints for collision avoidance"]}),"\n",(0,t.jsx)(e.h3,{id:"local-replanning",children:"Local Replanning"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsxs)(e.em,{children:[(0,t.jsx)(e.em,{children:"D"})," Algorithm"]}),"*: Incremental path replanning\n",(0,t.jsxs)(e.em,{children:[(0,t.jsx)(e.em,{children:"D"})," Lite"]}),"*: Simpler version of D*\n",(0,t.jsxs)(e.em,{children:[(0,t.jsx)(e.em,{children:"ARA"})," (Anytime Repairing A"]}),")**: Anytime algorithm with cost bounds"]}),"\n",(0,t.jsx)(e.h2,{id:"bipedal-locomotion-planning",children:"Bipedal Locomotion Planning"}),"\n",(0,t.jsx)(e.h3,{id:"walking-pattern-generation",children:"Walking Pattern Generation"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Predefined Gaits"}),": Fixed walking patterns for stable locomotion\n",(0,t.jsx)(e.strong,{children:"Online Gait Generation"}),": Real-time adaptation to terrain and conditions\n",(0,t.jsx)(e.strong,{children:"Footstep Planning"}),": Determine where to place feet"]}),"\n",(0,t.jsx)(e.h3,{id:"zero-moment-point-zmp-planning",children:"Zero Moment Point (ZMP) Planning"}),"\n",(0,t.jsx)(e.p,{children:"ZMP-based planning ensures dynamic stability:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"ZMP_x = (M_x + F_z * h) / F_z\nZMP_y = (M_y + F_z * h) / F_z\n"})}),"\n",(0,t.jsx)(e.p,{children:"Where M_x, M_y are moments, F_z is vertical force, and h is height."}),"\n",(0,t.jsx)(e.h3,{id:"capture-point-planning",children:"Capture Point Planning"}),"\n",(0,t.jsx)(e.p,{children:"The capture point indicates where the robot must step to come to a stop:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"Capture Point = CoM Position + CoM Velocity * \u221a(Height / Gravity)\n"})}),"\n",(0,t.jsx)(e.h2,{id:"technical-depth-mathematical-foundations",children:"Technical Depth: Mathematical Foundations"}),"\n",(0,t.jsx)(e.h3,{id:"configuration-space-formulation",children:"Configuration Space Formulation"}),"\n",(0,t.jsx)(e.p,{children:"For a humanoid robot with n joints:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"C = SE(3) \xd7 S\xb9 \xd7 S\xb9 \xd7 ... \xd7 S\xb9  (for n joints)\n"})}),"\n",(0,t.jsx)(e.p,{children:"Where SE(3) represents the special Euclidean group (position and orientation) and S\xb9 represents joint angles."}),"\n",(0,t.jsx)(e.h3,{id:"collision-detection",children:"Collision Detection"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Bounding Volume Hierarchies (BVH)"}),": Hierarchical bounding volumes for efficient collision detection\n",(0,t.jsx)(e.strong,{children:"Separating Axis Theorem"}),": For convex object collision detection\n",(0,t.jsx)(e.strong,{children:"GJK Algorithm"}),": Gilbert-Johnson-Keerthi for distance computation"]}),"\n",(0,t.jsx)(e.h3,{id:"optimization-formulation",children:"Optimization Formulation"}),"\n",(0,t.jsx)(e.p,{children:"Trajectory optimization as a constrained optimization problem:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"min \u222b\u2080\u1d40 [q\u0308(t)\u1d40H(t)q\u0308(t) + q\u0307(t)\u1d40R(t)q\u0307(t) + q(t)\u1d40Q(t)q(t)] dt\ns.t. f(q, q\u0307, q\u0308, t) = 0  (system dynamics)\n     g(q, q\u0307, q\u0308, t) \u2264 0  (inequality constraints)\n     q(0) = q_start, q(T) = q_goal  (boundary conditions)\n"})}),"\n",(0,t.jsx)(e.h2,{id:"practical-applications",children:"Practical Applications"}),"\n",(0,t.jsx)(e.h3,{id:"navigation-in-human-environments",children:"Navigation in Human Environments"}),"\n",(0,t.jsx)(e.p,{children:"Humanoid robots must navigate spaces designed for humans:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Doorways and corridors"}),"\n",(0,t.jsx)(e.li,{children:"Stairs and ramps"}),"\n",(0,t.jsx)(e.li,{children:"Furniture and obstacles"}),"\n",(0,t.jsx)(e.li,{children:"Moving humans and objects"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"manipulation-motion-planning",children:"Manipulation Motion Planning"}),"\n",(0,t.jsx)(e.p,{children:"Coordinating arm movements with balance:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Reaching without losing stability"}),"\n",(0,t.jsx)(e.li,{children:"Avoiding self-collisions"}),"\n",(0,t.jsx)(e.li,{children:"Coordinated multi-limb motion"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"multi-modal-locomotion",children:"Multi-modal Locomotion"}),"\n",(0,t.jsx)(e.p,{children:"Planning for different types of movement:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Walking"}),"\n",(0,t.jsx)(e.li,{children:"Crawling"}),"\n",(0,t.jsx)(e.li,{children:"Climbing"}),"\n",(0,t.jsx)(e.li,{children:"Assisted movement"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"challenges",children:"Challenges"}),"\n",(0,t.jsx)(e.h3,{id:"computational-complexity",children:"Computational Complexity"}),"\n",(0,t.jsx)(e.p,{children:"High-dimensional configuration spaces require significant computational resources."}),"\n",(0,t.jsx)(e.h3,{id:"real-time-performance",children:"Real-time Performance"}),"\n",(0,t.jsx)(e.p,{children:"Planning algorithms must run in real-time for responsive behavior."}),"\n",(0,t.jsx)(e.h3,{id:"uncertainty-handling",children:"Uncertainty Handling"}),"\n",(0,t.jsx)(e.p,{children:"Sensing and modeling uncertainties affect planning reliability."}),"\n",(0,t.jsx)(e.h3,{id:"dynamic-environments",children:"Dynamic Environments"}),"\n",(0,t.jsx)(e.p,{children:"Moving obstacles and changing environments require continuous replanning."}),"\n",(0,t.jsx)(e.h2,{id:"figure-list",children:"Figure List"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Figure 7.1"}),": Configuration space representation for humanoid robot"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Figure 7.2"}),": RRT algorithm visualization"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Figure 7.3"}),": Trajectory generation profiles"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Figure 7.4"}),": ZMP and Capture Point concepts"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Figure 7.5"}),": Obstacle avoidance strategies"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"code-example-motion-planning-implementation",children:"Code Example: Motion Planning Implementation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom typing import List, Tuple, Optional, Callable\nfrom dataclasses import dataclass\nimport matplotlib.pyplot as plt\nfrom scipy.spatial.distance import euclidean\nimport random\n\n@dataclass\nclass Node:\n    """Node in the motion planning tree"""\n    config: np.ndarray  # Configuration (position + orientation)\n    parent: Optional[\'Node\'] = None\n    cost: float = 0.0\n    heuristic: float = 0.0\n\n    def __lt__(self, other):\n        return (self.cost + self.heuristic) < (other.cost + other.heuristic)\n\nclass RRTPlanner:\n    """Rapidly-exploring Random Tree planner for motion planning"""\n\n    def __init__(self,\n                 start: np.ndarray,\n                 goal: np.ndarray,\n                 bounds: Tuple[Tuple[float, float], Tuple[float, float]],\n                 step_size: float = 0.1,\n                 max_iterations: int = 10000):\n        self.start = Node(start.copy())\n        self.goal = Node(goal.copy())\n        self.bounds = bounds  # ((x_min, x_max), (y_min, y_max))\n        self.step_size = step_size\n        self.max_iterations = max_iterations\n\n        # Tree structure\n        self.nodes = [self.start]\n        self.goal_found = False\n\n    def distance(self, config1: np.ndarray, config2: np.ndarray) -> float:\n        """Calculate distance between two configurations"""\n        return np.linalg.norm(config1 - config2)\n\n    def random_config(self) -> np.ndarray:\n        """Generate random configuration within bounds"""\n        x = random.uniform(self.bounds[0][0], self.bounds[0][1])\n        y = random.uniform(self.bounds[1][0], self.bounds[1][1])\n        return np.array([x, y])\n\n    def nearest_node(self, config: np.ndarray) -> Node:\n        """Find nearest node in tree to given configuration"""\n        distances = [self.distance(node.config, config) for node in self.nodes]\n        nearest_idx = np.argmin(distances)\n        return self.nodes[nearest_idx]\n\n    def steer(self, from_node: Node, to_config: np.ndarray) -> np.ndarray:\n        """Steer from one configuration towards another"""\n        direction = to_config - from_node.config\n        distance = np.linalg.norm(direction)\n\n        if distance <= self.step_size:\n            return to_config\n        else:\n            return from_node.config + (direction / distance) * self.step_size\n\n    def is_collision_free(self, config: np.ndarray) -> bool:\n        """Check if configuration is collision-free (simplified)"""\n        # In a real implementation, this would check against obstacles\n        # For this example, we\'ll assume no obstacles\n        return True\n\n    def plan(self) -> Optional[List[np.ndarray]]:\n        """Plan path using RRT algorithm"""\n        for i in range(self.max_iterations):\n            # Sample random configuration\n            rand_config = self.random_config()\n\n            # Find nearest node\n            nearest = self.nearest_node(rand_config)\n\n            # Steer towards random configuration\n            new_config = self.steer(nearest, rand_config)\n\n            # Check collision\n            if self.is_collision_free(new_config):\n                # Create new node\n                new_node = Node(new_config.copy())\n                new_node.parent = nearest\n                new_node.cost = nearest.cost + self.distance(nearest.config, new_config)\n\n                # Add to tree\n                self.nodes.append(new_node)\n\n                # Check if goal reached\n                if self.distance(new_config, self.goal.config) < self.step_size:\n                    self.goal_found = True\n                    return self.extract_path(new_node)\n\n        return None  # No path found\n\n    def extract_path(self, goal_node: Node) -> List[np.ndarray]:\n        """Extract path from goal node back to start"""\n        path = []\n        current = goal_node\n        while current is not None:\n            path.append(current.config.copy())\n            current = current.parent\n        return path[::-1]  # Reverse to get start-to-goal path\n\nclass TrajectoryGenerator:\n    """Generate smooth trajectories from path waypoints"""\n\n    def __init__(self, max_velocity: float = 1.0, max_acceleration: float = 2.0):\n        self.max_velocity = max_velocity\n        self.max_acceleration = max_acceleration\n\n    def generate_polynomial_trajectory(self, waypoints: List[np.ndarray],\n                                    times: List[float]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        """Generate cubic polynomial trajectory between waypoints"""\n        if len(waypoints) < 2:\n            return np.array([]), np.array([]), np.array([])\n\n        # Time intervals between waypoints\n        dt = np.diff(times)\n\n        # Positions, velocities, and accelerations\n        positions = []\n        velocities = []\n        accelerations = []\n\n        # For each segment\n        for i in range(len(waypoints) - 1):\n            start_pos = waypoints[i]\n            end_pos = waypoints[i + 1]\n            segment_time = dt[i]\n\n            # Cubic polynomial coefficients for smooth transition\n            # q(t) = a0 + a1*t + a2*t^2 + a3*t^3\n            a0 = start_pos\n            a1 = 0  # Assuming zero initial velocity\n            a2 = 3 * (end_pos - start_pos) / (segment_time ** 2)\n            a3 = -2 * (end_pos - start_pos) / (segment_time ** 3)\n\n            # Generate points along the trajectory\n            t_segment = np.linspace(0, segment_time, int(segment_time * 100) + 1)\n\n            for t in t_segment:\n                pos = a0 + a1 * t + a2 * t**2 + a3 * t**3\n                vel = a1 + 2 * a2 * t + 3 * a3 * t**2\n                acc = 2 * a2 + 6 * a3 * t\n\n                positions.append(pos)\n                velocities.append(vel)\n                accelerations.append(acc)\n\n        return np.array(positions), np.array(velocities), np.array(accelerations)\n\n    def velocity_smoothing(self, path: List[np.ndarray],\n                          max_vel: float = 1.0,\n                          max_acc: float = 2.0) -> List[Tuple[np.ndarray, float]]:\n        """Apply velocity smoothing to path"""\n        if len(path) < 2:\n            return [(path[0], 0.0)] if path else []\n\n        smoothed_path = []\n\n        for i in range(len(path)):\n            if i == 0:\n                # First point\n                smoothed_path.append((path[i], 0.0))\n            elif i == len(path) - 1:\n                # Last point - zero velocity\n                smoothed_path.append((path[i], 0.0))\n            else:\n                # Intermediate points\n                prev_pos = path[i-1]\n                curr_pos = path[i]\n                next_pos = path[i+1]\n\n                # Calculate direction and distance\n                dist_to_prev = np.linalg.norm(curr_pos - prev_pos)\n                dist_to_next = np.linalg.norm(next_pos - curr_pos)\n\n                # Determine appropriate velocity based on clearance\n                velocity = min(max_vel, max(0.1, max(dist_to_prev, dist_to_next) * max_vel / 2))\n\n                smoothed_path.append((curr_pos, velocity))\n\n        return smoothed_path\n\nclass HumanoidMotionPlanner:\n    """Motion planner specifically designed for humanoid robots"""\n\n    def __init__(self, num_joints: int = 20):\n        self.num_joints = num_joints\n        self.balance_constraint = True  # Whether to consider balance\n        self.max_joint_velocity = 5.0  # rad/s\n        self.max_joint_acceleration = 10.0  # rad/s\xb2\n\n    def plan_reaching_motion(self, start_config: np.ndarray,\n                           target_pos: np.ndarray,\n                           target_orientation: Optional[np.ndarray] = None) -> Optional[List[np.ndarray]]:\n        """Plan motion for reaching a target position"""\n        if len(start_config) != self.num_joints:\n            raise ValueError(f"Start configuration must have {self.num_joints} joints")\n\n        # Simplified reaching motion planning\n        # In reality, this would involve inverse kinematics and full motion planning\n\n        # For this example, we\'ll create a simple linear interpolation\n        # in joint space (not ideal, but demonstrates the concept)\n\n        # This is a simplified example - real reaching would use:\n        # 1. Inverse kinematics to find target configuration\n        # 2. Motion planning to avoid obstacles\n        # 3. Balance constraint checking\n\n        target_config = start_config.copy()\n        # Modify only the arm joints for reaching (simplified)\n        for i in range(6, 12):  # Assuming arm joints are indices 6-11\n            if i < len(target_config):\n                target_config[i] += random.uniform(-0.5, 0.5)  # Random adjustment\n\n        # Create trajectory by interpolating between start and target\n        steps = 50\n        trajectory = []\n        for step in range(steps + 1):\n            ratio = step / steps\n            config = start_config + ratio * (target_config - start_config)\n            trajectory.append(config)\n\n        return trajectory\n\n    def plan_walking_trajectory(self, start_pos: np.ndarray,\n                              goal_pos: np.ndarray,\n                              step_length: float = 0.3) -> List[np.ndarray]:\n        """Plan a simple walking trajectory"""\n        # Calculate number of steps needed\n        distance = np.linalg.norm(goal_pos - start_pos)\n        num_steps = int(distance / step_length)\n\n        if num_steps == 0:\n            return [start_pos]\n\n        # Generate intermediate waypoints\n        trajectory = []\n        for i in range(num_steps + 1):\n            ratio = i / num_steps\n            waypoint = start_pos + ratio * (goal_pos - start_pos)\n            trajectory.append(waypoint)\n\n        return trajectory\n\n    def check_balance_constraint(self, config: np.ndarray) -> bool:\n        """Check if configuration maintains balance"""\n        # Simplified balance check\n        # In reality, this would compute center of mass and check against support polygon\n        return True  # Placeholder\n\n    def optimize_trajectory(self, trajectory: List[np.ndarray]) -> List[np.ndarray]:\n        """Optimize trajectory for smoothness and efficiency"""\n        if len(trajectory) < 3:\n            return trajectory\n\n        # Apply smoothing using a simple averaging filter\n        optimized = [trajectory[0]]  # Keep first point\n\n        for i in range(1, len(trajectory) - 1):\n            # Average with neighbors for smoothing\n            smoothed_point = (trajectory[i-1] + 2*trajectory[i] + trajectory[i+1]) / 4\n            optimized.append(smoothed_point)\n\n        optimized.append(trajectory[-1])  # Keep last point\n        return optimized\n\ndef demonstrate_motion_planning():\n    """Demonstrate motion planning concepts"""\n    print("Motion Planning Demonstration")\n    print("=" * 40)\n\n    # Example 1: RRT Planning in 2D\n    print("\\n1. RRT Path Planning Example:")\n    start = np.array([0.0, 0.0])\n    goal = np.array([5.0, 5.0])\n    bounds = ((-1.0, 6.0), (-1.0, 6.0))\n\n    rrt = RRTPlanner(start, goal, bounds, step_size=0.2, max_iterations=1000)\n    path = rrt.plan()\n\n    if path:\n        print(f"  Found path with {len(path)} waypoints")\n        print(f"  Path length: {sum(np.linalg.norm(path[i+1]-path[i]) for i in range(len(path)-1)):.2f}")\n\n        # Generate smooth trajectory\n        times = [i * 0.1 for i in range(len(path))]\n        traj_gen = TrajectoryGenerator(max_velocity=1.0, max_acceleration=2.0)\n        positions, velocities, accelerations = traj_gen.generate_polynomial_trajectory(path, times)\n\n        print(f"  Generated trajectory with {len(positions)} points")\n    else:\n        print("  No path found")\n\n    # Example 2: Humanoid-specific planning\n    print("\\n2. Humanoid Motion Planning Example:")\n    humanoid_planner = HumanoidMotionPlanner(num_joints=20)\n\n    start_config = np.zeros(20)  # Starting configuration\n    target_pos = np.array([1.0, 0.5, 0.8])  # Target position in workspace\n\n    reaching_trajectory = humanoid_planner.plan_reaching_motion(start_config, target_pos)\n    if reaching_trajectory:\n        print(f"  Generated reaching trajectory with {len(reaching_trajectory)} configurations")\n\n        # Optimize trajectory\n        optimized = humanoid_planner.optimize_trajectory(reaching_trajectory)\n        print(f"  Optimized trajectory with {len(optimized)} configurations")\n\n    # Example 3: Walking trajectory\n    print("\\n3. Walking Trajectory Example:")\n    start_pos = np.array([0.0, 0.0])\n    goal_pos = np.array([3.0, 2.0])\n\n    walking_traj = humanoid_planner.plan_walking_trajectory(start_pos, goal_pos)\n    print(f"  Walking trajectory with {len(walking_traj)} steps")\n\n    # Calculate step statistics\n    if len(walking_traj) > 1:\n        total_distance = sum(np.linalg.norm(walking_traj[i+1]-walking_traj[i])\n                           for i in range(len(walking_traj)-1))\n        print(f"  Total walking distance: {total_distance:.2f}m")\n        print(f"  Average step length: {total_distance/max(1, len(walking_traj)-1):.2f}m")\n\n    # Example 4: Trajectory smoothing\n    print("\\n4. Trajectory Smoothing Example:")\n    # Create a zigzag path\n    zigzag_path = []\n    for i in range(10):\n        x = i * 0.5\n        y = 2.0 + (1.0 if i % 2 == 0 else -1.0) * 0.5\n        zigzag_path.append(np.array([x, y]))\n\n    smoothed = TrajectoryGenerator().velocity_smoothing(zigzag_path, max_vel=0.5)\n    print(f"  Original path: {len(zigzag_path)} points")\n    print(f"  Smoothed path: {len(smoothed)} points with velocity information")\n\ndef analyze_planning_performance():\n    """Analyze motion planning performance metrics"""\n    metrics = {\n        \'planning_time\': [],\n        \'path_length\': [],\n        \'smoothness\': [],\n        \'success_rate\': 0\n    }\n\n    # Simulate multiple planning scenarios\n    successful_plans = 0\n    total_plans = 10\n\n    for i in range(total_plans):\n        # Simulate planning time (in seconds)\n        planning_time = random.uniform(0.01, 0.5)\n        metrics[\'planning_time\'].append(planning_time)\n\n        # Simulate path length\n        path_length = random.uniform(1.0, 10.0)\n        metrics[\'path_length\'].append(path_length)\n\n        # Simulate smoothness (lower is smoother)\n        smoothness = random.uniform(0.1, 2.0)\n        metrics[\'smoothness\'].append(smoothness)\n\n        # Random success/failure\n        if random.random() > 0.1:  # 90% success rate\n            successful_plans += 1\n\n    metrics[\'success_rate\'] = successful_plans / total_plans\n\n    print("\\n5. Planning Performance Analysis:")\n    print(f"  Success Rate: {metrics[\'success_rate\']*100:.1f}%")\n    print(f"  Average Planning Time: {np.mean(metrics[\'planning_time\']):.3f}s")\n    print(f"  Average Path Length: {np.mean(metrics[\'path_length\']):.2f}m")\n    print(f"  Average Smoothness: {np.mean(metrics[\'smoothness\']):.2f}")\n    print(f"  Planning Time Std: {np.std(metrics[\'planning_time\']):.3f}s")\n\nif __name__ == "__main__":\n    demonstrate_motion_planning()\n    analyze_planning_performance()\n\n    print("\\nMotion Planning and Locomotion - Chapter 7 Complete!")\n'})}),"\n",(0,t.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Implement a simple A* algorithm for path planning in a 2D grid environment."}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Design a trajectory generator that creates minimum-jerk trajectories for a 6-DOF arm."}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Create a motion planner that considers both collision avoidance and balance constraints for a simple humanoid model."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary-1",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"This chapter provided a comprehensive overview of motion planning for humanoid robots, covering fundamental algorithms, trajectory generation techniques, and the unique challenges of planning for bipedal locomotion. We explored sampling-based algorithms like RRT, optimization-based approaches, and trajectory generation methods. The mathematical foundations and practical examples presented will help in developing motion planning systems for specific humanoid robot applications. Understanding these concepts is essential for creating robots that can navigate complex environments safely and efficiently."})]})}function p(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>s});var t=i(6540);const o={},a=t.createContext(o);function r(n){const e=t.useContext(a);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:r(n.components),t.createElement(a.Provider,{value:e},n.children)}}}]);